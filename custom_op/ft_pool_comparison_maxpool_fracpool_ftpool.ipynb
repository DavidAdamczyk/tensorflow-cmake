{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tf1_13/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/miniconda3/envs/tf1_13/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/miniconda3/envs/tf1_13/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/miniconda3/envs/tf1_13/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/miniconda3/envs/tf1_13/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/miniconda3/envs/tf1_13/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from user_ops import ft_pool\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import math\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join('..', '..', 'keras_frac'))\n",
    "from fractional_maxpooling import FractionalPooling2D\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class max_pool_net:\n",
    "    def __init__(self, opt, batch_input_shape, classes, k_size=(3,3), filters=2, blocks=2):\n",
    "        self.model = keras.models.Sequential()\n",
    "        self.model.add(keras.layers.InputLayer(batch_input_shape=batch_input_shape))\n",
    "        self.model.add(keras.layers.Conv2D(filters, k_size, activation='relu', padding='same'))\n",
    "        self.model.add(keras.layers.Conv2D(filters, k_size, activation='relu', padding='same'))\n",
    "        self.model.add(keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "        for i in range(2, blocks+1):\n",
    "            self.model.add(keras.layers.Conv2D(filters*i, k_size, activation='relu', padding='same'))\n",
    "            self.model.add(keras.layers.Conv2D(filters*i, k_size, activation='relu', padding='same'))\n",
    "            self.model.add(keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "        self.model.add(keras.layers.Flatten())\n",
    "        self.model.add(keras.layers.Dense(classes, activation='softmax'))\n",
    "        self.model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        print(self.model.summary())\n",
    "    \n",
    "    def train(self, batch_size, epochs, datagen=None, train_data=None, callbacks=None):\n",
    "        if datagen is None and train_data is None:\n",
    "            print('neither data or generator was passed')\n",
    "        elif datagen is None and train_data is not None:\n",
    "            print('training on array data, network type:', type(self).__name__)\n",
    "            self.history = self.model.fit(x = train_data[0], y = train_data[1], validation_data=train_data[2:], batch_size=batch_size, epochs=epochs, callbacks=callbacks)\n",
    "        else:\n",
    "            print('training on datagen data, network type:', type(self).__name__)\n",
    "            self.history = self.model.fit_generator(datagen, validation_data=train_data[2:], batch_size=batch_size, epochs=epochs, callbacks=callbacks)\n",
    "        self.weights = self.model.get_weights()\n",
    "    \n",
    "    def restart_session(self):\n",
    "        keras.backend.clear_session()\n",
    "        \n",
    "    def get_history(self):\n",
    "        return self.history\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def load_weights(self):\n",
    "        self.model.load_weights(self.weights)\n",
    "\n",
    "        \n",
    "class frac_pool_net(max_pool_net):\n",
    "    def __init__(self, opt, batch_input_shape, classes, k_size=(3,3), filters=2, blocks=2):\n",
    "        ratio = 1.35 # 1.33 blocks=3\n",
    "        self.model = keras.models.Sequential()\n",
    "        self.model.add(keras.layers.InputLayer(batch_input_shape=batch_input_shape))\n",
    "        self.model.add(keras.layers.Conv2D(filters, k_size, activation='relu', padding='same'))\n",
    "        self.model.add(FractionalPooling2D(pool_ratio=(1, ratio, ratio, 1),pseudo_random = True, overlap=False))\n",
    "        self.model.add(keras.layers.Conv2D(filters, k_size, activation='relu', padding='same'))\n",
    "        self.model.add(FractionalPooling2D(pool_ratio=(1, ratio, ratio, 1),pseudo_random = True, overlap=False))\n",
    "        for i in range(2, blocks+1):\n",
    "            self.model.add(keras.layers.Conv2D(filters*i, k_size, activation='relu', padding='same'))\n",
    "            self.model.add(FractionalPooling2D(pool_ratio=(1, ratio, ratio, 1),pseudo_random = True, overlap=False))\n",
    "            self.model.add(keras.layers.Conv2D(filters*i, k_size, activation='relu', padding='same'))\n",
    "            self.model.add(FractionalPooling2D(pool_ratio=(1, ratio, ratio, 1),pseudo_random = True, overlap=False))\n",
    "        self.model.add(keras.layers.Flatten())\n",
    "        self.model.add(keras.layers.Dense(classes, activation='softmax'))\n",
    "        self.model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        print(self.model.summary())\n",
    "    \n",
    "    \n",
    "class ft_pool_net(max_pool_net):\n",
    "    def __init__(self, opt, batch_input_shape, classes, k_size=(3,3), filters=2, blocks=2):\n",
    "        strides=(math.sqrt(2), math.sqrt(2))\n",
    "        pool_size=(math.sqrt(2)*2, math.sqrt(2)*2)\n",
    "        self.model = keras.models.Sequential()\n",
    "        self.model.add(keras.layers.InputLayer(batch_input_shape=batch_input_shape))\n",
    "        self.model.add(keras.layers.Conv2D(filters, k_size, activation='relu', padding='same',))\n",
    "        self.model.add(keras.layers.Lambda(lambda x: ft_pool(x, strides, pool_size)))\n",
    "        self.model.add(keras.layers.Conv2D(filters, k_size, activation='relu', padding='same'))\n",
    "        self.model.add(keras.layers.Lambda(lambda x: ft_pool(x, strides, pool_size)))\n",
    "        for i in range(2, blocks+1):\n",
    "            self.model.add(keras.layers.Conv2D(filters*i, k_size, activation='relu', padding='same'))\n",
    "            self.model.add(keras.layers.Lambda(lambda x: ft_pool(x, strides, pool_size)))\n",
    "            self.model.add(keras.layers.Conv2D(filters*i, k_size, activation='relu', padding='same'))\n",
    "            self.model.add(keras.layers.Lambda(lambda x: ft_pool(x, strides, pool_size)))\n",
    "        self.model.add(keras.layers.Flatten())\n",
    "        self.model.add(keras.layers.Dense(classes, activation='softmax'))\n",
    "        self.model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        print(self.model.summary())\n",
    "        \n",
    "class avg_pool_net(max_pool_net):\n",
    "    def __init__(self, opt, batch_input_shape, classes, k_size=(3,3), filters=2, blocks=2):\n",
    "        pool_size=2\n",
    "        self.model = keras.models.Sequential()\n",
    "        self.model.add(keras.layers.InputLayer(batch_input_shape=batch_input_shape))\n",
    "        self.model.add(keras.layers.Conv2D(filters, k_size, activation='relu', padding='same',))\n",
    "        self.model.add(keras.layers.AveragePooling2D(pool_size=(pool_size, pool_size), strides=(2,2), padding='same'))\n",
    "        self.model.add(keras.layers.Conv2D(filters, k_size, activation='relu', padding='same'))\n",
    "        for i in range(2, blocks+1):\n",
    "            self.model.add(keras.layers.Conv2D(filters*i, k_size, activation='relu', padding='same'))\n",
    "            self.model.add(keras.layers.AveragePooling2D(pool_size=(pool_size, pool_size), strides=(2,2), padding='same'))\n",
    "            self.model.add(keras.layers.Conv2D(filters*i, k_size, activation='relu', padding='same'))\n",
    "        self.model.add(keras.layers.Flatten())\n",
    "        self.model.add(keras.layers.Dense(classes, activation='softmax'))\n",
    "        self.model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        print(self.model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 100\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1_13/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (100, 32, 32, 2)          56        \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (100, 23, 23, 2)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (100, 23, 23, 2)          38        \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (100, 16, 16, 2)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (100, 16, 16, 4)          76        \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (100, 11, 11, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (100, 11, 11, 4)          148       \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (100, 8, 8, 4)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (100, 256)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 10)                 2570      \n",
      "=================================================================\n",
      "Total params: 2,888\n",
      "Trainable params: 2,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "training on array data, network type: ft_pool_net\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1_13/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 38s 752us/step - loss: 2.2607 - accuracy: 0.1366 - val_loss: 2.0787 - val_accuracy: 0.2590\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 39s 770us/step - loss: 1.8985 - accuracy: 0.3092 - val_loss: 1.7377 - val_accuracy: 0.3747\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 38s 753us/step - loss: 1.6954 - accuracy: 0.3829 - val_loss: 1.6338 - val_accuracy: 0.4056\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 38s 757us/step - loss: 1.6254 - accuracy: 0.4078 - val_loss: 1.6175 - val_accuracy: 0.4135\n",
      "Epoch 5/10\n",
      "20300/50000 [===========>..................] - ETA: 22s - loss: 1.6018 - accuracy: 0.4208"
     ]
    }
   ],
   "source": [
    "ft_net = ft_pool_net(keras.optimizers.Adadelta(), (BATCH_SIZE,) + x_train.shape[1:], y_train.shape[1], blocks=2)\n",
    "ft_net.train(BATCH_SIZE, EPOCHS, train_data=(x_train, y_train, x_test, y_test), callbacks=[keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, verbose=1)])\n",
    "ft_net.restart_session()\n",
    "\n",
    "avg_net = avg_pool_net(keras.optimizers.Adadelta(), (BATCH_SIZE,) + x_train.shape[1:], y_train.shape[1], blocks=2)\n",
    "avg_net.train(BATCH_SIZE, EPOCHS, train_data=(x_train, y_train, x_test, y_test), callbacks=[keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, verbose=1)])\n",
    "avg_net.restart_session()\n",
    "\n",
    "max_net = max_pool_net(keras.optimizers.Adadelta(), (BATCH_SIZE,) + x_train.shape[1:], y_train.shape[1], blocks=2)\n",
    "max_net.train(BATCH_SIZE, EPOCHS, train_data=(x_train, y_train, x_test, y_test), callbacks=[keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, verbose=1)])\n",
    "max_net.restart_session()\n",
    "\n",
    "frac_net = frac_pool_net(keras.optimizers.Adadelta(), (BATCH_SIZE,) + x_train.shape[1:], y_train.shape[1], blocks=2)\n",
    "frac_net.train(BATCH_SIZE, EPOCHS, train_data=(x_train, y_train, x_test, y_test), callbacks=[keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, verbose=1)])\n",
    "frac_net.restart_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline best 2x max pool = 53.19%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(max_net.get_history().history['val_accuracy'], 'r')\n",
    "plt.plot(frac_net.get_history().history['val_accuracy'], 'g')\n",
    "plt.plot(ft_net.get_history().history['val_accuracy'], 'b')\n",
    "plt.plot(avg_net.get_history().history['val_accuracy'], 'c')\n",
    "plt.show()\n",
    "# petruv pristup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(max_net.get_history().history['val_accuracy'], 'r')\n",
    "plt.plot(frac_net.get_history().history['val_accuracy'], 'g')\n",
    "plt.plot(ft_net.get_history().history['val_accuracy'], 'b')\n",
    "plt.plot(avg_net.get_history().history['val_accuracy'], 'c')\n",
    "plt.show()\n",
    "# muj pristup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(max_net.get_history().history['val_accuracy'], 'r')\n",
    "plt.plot(frac_net.get_history().history['val_accuracy'], 'g')\n",
    "plt.plot(ft_net.get_history().history['val_accuracy'], 'b')\n",
    "plt.plot(avg_net.get_history().history['val_accuracy'], 'c')\n",
    "plt.show()\n",
    "# 5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ft_net = ft_pool_net(keras.optimizers.Adadelta(), (BATCH_SIZE,) + x_train.shape[1:], y_train.shape[1], blocks=2)\n",
    "ft_net.train(BATCH_SIZE, EPOCHS, train_data=(x_train, y_train, x_test, y_test), callbacks=[keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, verbose=1)])\n",
    "ft_net.restart_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(max_net.get_history().history['val_accuracy'], 'r')\n",
    "plt.plot(frac_net.get_history().history['val_accuracy'], 'g')\n",
    "plt.plot(ft_net.get_history().history['val_accuracy'], 'b')\n",
    "plt.plot(avg_net.get_history().history['val_accuracy'], 'c')\n",
    "plt.show()\n",
    "# 2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_net = avg_pool_net(keras.optimizers.Adadelta(), (BATCH_SIZE,) + x_train.shape[1:], y_train.shape[1], blocks=2)\n",
    "avg_net.train(BATCH_SIZE, EPOCHS, train_data=(x_train, y_train, x_test, y_test), callbacks=[keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, verbose=1)])\n",
    "avg_net.restart_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(max_net.get_history().history['val_accuracy'], 'r')\n",
    "plt.plot(frac_net.get_history().history['val_accuracy'], 'g')\n",
    "plt.plot(ft_net.get_history().history['val_accuracy'], 'b')\n",
    "plt.plot(avg_net.get_history().history['val_accuracy'], 'c')\n",
    "plt.show()\n",
    "# 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_net = avg_pool_net(keras.optimizers.Adadelta(), (BATCH_SIZE,) + x_train.shape[1:], y_train.shape[1], blocks=2)\n",
    "avg_net.train(BATCH_SIZE, EPOCHS, train_data=(x_train, y_train, x_test, y_test), callbacks=[keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, verbose=1)])\n",
    "avg_net.restart_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(max_net.get_history().history['val_accuracy'], 'r')\n",
    "plt.plot(frac_net.get_history().history['val_accuracy'], 'g')\n",
    "plt.plot(ft_net.get_history().history['val_accuracy'], 'b')\n",
    "plt.plot(avg_net.get_history().history['val_accuracy'], 'c')\n",
    "plt.show()\n",
    "# 4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_net = avg_pool_net(keras.optimizers.Adadelta(), (BATCH_SIZE,) + x_train.shape[1:], y_train.shape[1], blocks=2)\n",
    "avg_net.train(BATCH_SIZE, EPOCHS, train_data=(x_train, y_train, x_test, y_test), callbacks=[keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, verbose=1)])\n",
    "avg_net.restart_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(max_net.get_history().history['val_accuracy'], 'r')\n",
    "plt.plot(frac_net.get_history().history['val_accuracy'], 'g')\n",
    "plt.plot(ft_net.get_history().history['val_accuracy'], 'b')\n",
    "plt.plot(avg_net.get_history().history['val_accuracy'], 'c')\n",
    "plt.show()\n",
    "# 6x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_net = avg_pool_net(keras.optimizers.Adadelta(), (BATCH_SIZE,) + x_train.shape[1:], y_train.shape[1], blocks=2)\n",
    "avg_net.train(BATCH_SIZE, EPOCHS, train_data=(x_train, y_train, x_test, y_test), callbacks=[keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, verbose=1)])\n",
    "avg_net.restart_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(max_net.get_history().history['val_accuracy'], 'r')\n",
    "plt.plot(frac_net.get_history().history['val_accuracy'], 'g')\n",
    "plt.plot(ft_net.get_history().history['val_accuracy'], 'b')\n",
    "plt.plot(avg_net.get_history().history['val_accuracy'], 'c')\n",
    "plt.show()\n",
    "# 7x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_net = ft_pool_net(keras.optimizers.Adadelta(), (BATCH_SIZE,) + x_train.shape[1:], y_train.shape[1], blocks=2)\n",
    "ft_net.train(BATCH_SIZE, EPOCHS, train_data=(x_train, y_train, x_test, y_test), callbacks=[keras.callbacks.ReduceLROnPlateau(patience=5, factor=.5, verbose=1)])\n",
    "ft_net.restart_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(max_net.get_history().history['val_accuracy'], 'r')\n",
    "plt.plot(frac_net.get_history().history['val_accuracy'], 'g')\n",
    "plt.plot(ft_net.get_history().history['val_accuracy'], 'b')\n",
    "plt.plot(avg_net.get_history().history['val_accuracy'], 'c')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
